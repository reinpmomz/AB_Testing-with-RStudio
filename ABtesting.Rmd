---
title: "AB_Testing"
output:
  html_document: 
    keep_md: yes
  word_document: default
  pdf_document: default
---


```{r Import relevant packages}
#Import relevant packages
library(stats)
library(psych)
library(ggplot2)
```

```{r loading dataset }
#loading the excel dataset with two sheets
library("readxl")
setwd('E:/Documents/Reinp/GitHub Respositories/AB_Testing-with-RStudio')
ds_sd<-read_excel('School data.xlsx', sheet = "Data")
View(ds_sd)
attach(ds_sd)

ds_sd1<-read_excel('School data.xlsx', sheet = "District names")
View(ds_sd1)
attach(ds_sd1)
```

```{r structure of data}
#learn more about the dataset
help(ds_sd)
??ds_sd
str(ds_sd)
class(ds_sd)
typeof(ds_sd) 
length(ds_sd)
names(ds_sd) #display variable names
#attributes(ds_sd) #names(ds_sd), class(ds_sd), row.names(ds_sd)
```

```{r distribution of input variables}
#distribution of input variables
table(ds_sd$district_id)
table(ds_sd1$"DISTRICT ID")
```

```{r unique}
#unique values per column
unique(ds_sd$district_id)
unique(ds_sd1$"DISTRICT ID")
```

```{r unique comments}
#district_id 200 in (ds_sd dataframe) is not in the (ds-sd1 dataframe)
#DISTRICT ID 1 in (ds_sd1 dataframe) is not in the (ds-sd dataframe)
#DISTRICT ID 2 in (ds_sd1 dataframe) is not in the (ds-sd dataframe)
#DISTRICT ID 112 in (ds_sd1 dataframe) is not in the (ds-sd dataframe)
```

```{r merge the data}
ds_sdmerge <- merge(ds_sd, ds_sd1, by.x = "district_id", by.y = "DISTRICT ID") #N/A. 
#This is default #Keep rows where there’s a match in both #innerjoin
View(ds_sdmerge)

ds_sdmerge1 <- merge(ds_sd, ds_sd1, by.x = "district_id", by.y = "DISTRICT ID", all.x = TRUE)
#Keep all rows from x, regardless of match in y #leftJoin even if there's no match in y
View(ds_sdmerge1)

ds_sdmerge2 <- merge(ds_sd, ds_sd1, by.x = "district_id", by.y = "DISTRICT ID", all.y = TRUE)
#Keep all rows from y, regardless of match in x #Rightjoin even if there's no match in x
View(ds_sdmerge2)

ds_sdmerge3 <- merge(ds_sd, ds_sd1, by.x = "district_id", by.y = "DISTRICT ID", all= TRUE)
#Keep all rows from x AND from y #Outerjoin 
View(ds_sdmerge3)

#We select default merge for the final data. It keeps rows where there’s a match in both. 
#we get a total of 6970 schools

```


```{r add column by Computing the total number of students enrolled and attended in each school}
#add total_enrolled column by computing the total number of student enrolled and total number 
#of attended in each school
#Get the total number of student enrolled in each school by adding enrolled_male_students 
#and enrolled_female_students columns

#Adding by equation
ds_sdmerge$total_enrolled=ds_sdmerge$enrolled_male_students + ds_sdmerge$enrolled_female_students
ds_sdmerge$total_attended=ds_sdmerge$attended_male + ds_sdmerge$attended_female

#transform() function
ds_sdmerge1 <- transform(ds_sdmerge1, total_enrolled = enrolled_male_students +
                    enrolled_female_students)
ds_sdmerge1 <- transform(ds_sdmerge1, total_attended = attended_male + attended_female)

#apply() function
ds_sdmerge2$total_enrolled <- apply(ds_sdmerge2[,c('enrolled_male_students',
                          'enrolled_female_students')], 1, function(x) sum(x))
ds_sdmerge2$total_attended <- apply(ds_sdmerge2[,c('attended_male', 'attended_female')], 1,
                              function(x) sum(x))

#tidyverse's dplyr
library(dplyr)
ds_sdmerge3 <- mutate(ds_sdmerge3, total_enrolled = enrolled_male_students +
                        enrolled_female_students)
ds_sdmerge3 <- mutate(ds_sdmerge3, total_attended = attended_male + attended_female)

```

```{r summary statistics}
#summary statistics
summary(ds_sdmerge) #summarizes the dataset
describe(ds_sdmerge)
```

```{r Create the school_id column}
#Create the school_id variable by first sorting the data within each district by the total
#number of enrollees per school. Let the ID be 1 for the school within each district with the
#highest number of enrolled students, 2 for the second highest and so on........

ds_sdmerge <- arrange(ds_sdmerge,district_id,desc(total_enrolled))


ds_sdmerger <- ds_sdmerge %>% 
  group_by(district_id) %>% 
  mutate(school_id = rank(desc(total_enrolled), ties.method = "first"))

View(ds_sdmerger)
head(ds_sdmerger)
tail(ds_sdmerger)

```

```{r outliers}
#Check the numeric variables for outliers.
describe(ds_sdmerger)

## We use boxplot to visualize for any outliers

boxplot(ds_sdmerger [, c("attended_male", "attended_female", "enrolled_male_students",
      "enrolled_female_students", "total_enrolled", "total_attended")], main="boxplots",
xlab="variables",
ylab="number of students",
col="orange",
border="brown", las = 2, cex.axis = 0.6, col.axis = 'blue', col.lab = 'red')

```

```{r outliers comments}
#From the boxplot above, outliers are present in form of negative count of students.
#There are negative values in enrolled_male_students and in enrolled_female_students leading 
#to a negative total_enrolled
```

```{r clean data from outliers}
#cleaning data from the outliers
ds_sdmerger1 <- ds_sdmerger[(ds_sdmerger[,8]>0),]
View(ds_sdmerger1)
describe(ds_sdmerger1)
```

```{r create Treatment-label column}
#Label values for the treatment variable appropriately (1 = Treatment, 0 = Control)
ds_sdmerger1$treatment_type <- factor(ds_sdmerger1$treatment, levels = c(0,1), 
                                      labels = c("control", "treatment"))
View(ds_sdmerger1)


which(is.na(ds_sdmerger1$total_attended)) #check for missing values

which(!complete.cases(ds_sdmerger1))
```

```{r barplot}
#Create a well labelled graphs showing the difference in attendance between treatment 
#and control schools.

bp1 <- barplot(tapply(ds_sdmerger1$attended_female, ds_sdmerger1$treatment_type, FUN=sum), 
    xlab="treatment_type",ylab="attended_female",col=c("lightblue", "green"), 
main="Sum Attended Female Barplot chart",border="brown" , col.axis = 'blue', col.lab = 'red',
cex.axis = 0.7, cex.lab = 0.8, las = 2, ylim=c(0, 800000))
text(bp1, 0, tapply(ds_sdmerger1$attended_female, ds_sdmerger1$treatment_type, FUN=sum), 
     cex=1,pos=3)


bp2 <- barplot(tapply(ds_sdmerger1$attended_male, ds_sdmerger1$treatment_type, FUN=sum),
    xlab="treatment_type",ylab="attended_male",col=c("yellow", "orange"),
    main="Sum Attended Male Barplot chart",border="brown" , col.axis = 'blue', col.lab = 'red',
    cex.axis = 0.7, cex.lab = 0.8, las = 2, ylim=c(0, 1000000))
text(bp2, 0, tapply(ds_sdmerger1$attended_male, ds_sdmerger1$treatment_type, FUN=sum), 
     cex=1,pos=3)


bp3 <- barplot(tapply(ds_sdmerger1$total_attended, ds_sdmerger1$treatment_type, FUN=sum), 
      xlab="treatment_type",ylab="total_attended",col=c("grey", "purple"),
  main="Total Sum Attended Barplot chart",border="brown" , col.axis = 'blue', col.lab = 'red',
  cex.axis = 0.7, cex.lab = 0.8, las = 2, ylim=c(0, 2000000))
text(bp3, 0, tapply(ds_sdmerger1$total_attended, ds_sdmerger1$treatment_type, FUN=sum), 
     cex=1,pos=3)
```

```{r boxplot}
#relationship between treatment_type and total_attended by means of a boxplot
boxplot(attended_female ~ treatment_type,
col=c("lightblue", "green"),ds_sdmerger1,
col.axis = 'blue', col.lab = 'red', border="brown",
main="Sum Attended Female BoxPlot")

boxplot(attended_male ~ treatment_type,
col=c("yellow", "orange"),ds_sdmerger1,
col.axis = 'blue', col.lab = 'red', border="brown",
main="Sum Attended Male BoxPlot")


boxplot(total_attended ~ treatment_type,
col=c("gray","purple"),ds_sdmerger1,
col.axis = 'blue', col.lab = 'red', border="brown",
main="Total Sum Attended BoxPlot")
```


```{r distribution}
#finding a fitting distribution for the total attended variable
library(car)
library(MASS) #So that distributions that must be non-zero can make sense of my data

qqp(ds_sdmerger1$total_attended+1, "norm", main="Normal model")

qqp(ds_sdmerger1$total_attended+1, "lnorm", main="LogNormal model") #lnorm means lognormal

# qqp requires estimates of the parameters of the negative binomial, Poisson
# and gamma distributions. You can generate estimates using the fitdistr
# function.

#negative binomial and gamma distributions can only handle positive numbers.
#Poisson distribution can only handle positive whole numbers. 
#Binomial and Poisson distributions are different from the others because they 
#are discrete rather than continuous, which means they quantify distinct, 
#countable events or the probability of these events

nbinom <- fitdistr(ds_sdmerger1$total_attended+1, "Negative Binomial")
qqp(ds_sdmerger1$total_attended+1, "nbinom", size = nbinom$estimate[[1]], mu =
      nbinom$estimate[[2]], main="Negative Binomial model")

pois <- fitdistr(ds_sdmerger1$total_attended+1, "Poisson")
qqp(ds_sdmerger1$total_attended+1, "pois", lambda=pois$estimate, main="Poisson model")

gamma <- fitdistr(ds_sdmerger1$total_attended+1, "gamma")
qqp(ds_sdmerger1$total_attended+1, "gamma", shape = gamma$estimate[[1]], rate =
      gamma$estimate[[2]], main="Gamma model")
```

```{r linear mixed model}
#Armed with the knowledge of which probability distribution fits best, 
#we can try fitting a model


#A mixed model is similar in many ways to a linear model. 
#It estimates the effects of one or more explanatory variables on a response variable.
#The output of a mixed model will give you a list of explanatory values, estimates and
#confidence intervals of their effect sizes, p-values for each effect, and 
#at least one measure of how well the model fits. 
#You should use a mixed model instead of a simple linear model when you have a variable 
#that describes your data sample as a subset of the data you could have collected.

#In a mixed model, we add one or more random effects to our fixed effects.
#These random effects essentially give structure to the error term. 
#this characterizes idiosyncratic variation that is due to individual differences.

#linear models are “fixed-effects-only” models. They have one or more fixed effects and a 
#general error term.

#If data is normally distributed, we can use a linear mixed model (LMM). 
#load the lme4 package and make a call to the function lmer. 
#The first argument to the function is a formula that takes the form y ~ x1 + x2 ...etc.,
#where y is the response variable and x1, x2, etc. are explanatory variables. 
#Random effects are added in with the explanatory variables. 
#Crossed random effects take the form (1 | r1) + (1 | r2) ... 
#while nested random effects take the form (1 | r1 / r2).

#The next argument is where you designate the data frame your variables come from. 
#This is where you can designate whether the mixed model will estimate the parameters
#using maximum likelihood or restricted maximum likelihood. 
#If your random effects are nested, or you have only one random effect, and if your data
#are balanced (i.e., similar sample sizes in each factor group) set REML to FALSE, 
#because you can use maximum likelihood. 
#If your random effects are crossed, don't set the REML argument because it defaults
#to TRUE anyway.
```


```{r lmmnull}
library(lme4)
#1.We construct the null model first. 
#H0 (called the null hypothesis ): There is no relationship between the two variables.

lmmtreatment.null <- lmer(total_attended ~ total_enrolled + (1 | district_id), 
                          data = ds_sdmerger1, REML = FALSE)
summary(lmmtreatment.null)

#The Anova function does a Wald test, which tells us how confident we are of our 
#estimate of the effect of total enrolled on total attended, and the p-value tells 
#me that I should not be confident at all.
Anova(lmmtreatment.null)
```

```{r lmmfull}
#2.we construct the full model next
#H1 (called the alternative hypothesis): There exist a relationship between the two variables.

lmmtreatment <- lmer(total_attended ~ treatment + total_enrolled + (1 | district_id), 
                          data = ds_sdmerger1, REML = FALSE)
summary(lmmtreatment)

#The Anova function tells us how confident we are of our estimate of the effect of 
#treatment and total enrolled on total attended, and the p-value tells 
#me that I should not be confident at all.
Anova(lmmtreatment)
```

```{r lmm}
lmmtreat <- lmer(total_attended ~ treatment + (1 | district_id), 
                          data = ds_sdmerger1, REML = FALSE)
summary(lmmtreat)

#The Anova function tells us how confident we are of our estimate of the effect of 
#treatment on total attended, and the p-value tells 
#me that I should not be confident at all.
Anova(lmmtreat)

#The coefficient “treatment” is the slope for the categorical effect of providing meals.
#7.691 means that to go from “control” to “treatment”, total attendance increases 
#by around 8 pupils.
#attendance is lower in control(no meals provided) than in treatment(meals provided), 
#by about 8 pupils.

#oftentimes, model intercepts are not particularly meaningful.
#But this Model intercept is 463.090. If you look back at the boxplot that we constructed
#earlier, you can see that the value 463.090 seems to fall halfway between control 
#and treatment(and this is indeed what this intercept represents). 
#It’s the average of our data for the informal condition

#compared to the other model with the fixed effect total enrolled added, the intercept
#is particularly off as we didn’t inform our model that there’s total enrolled in 
#our dataset. the intercept reduces to 406. The coefficient for the effect of treatment 
#increased to 8.406 from 7.691

#If you want to interpret these results, you’ll most likely need to report some kind 
#of p-value. 
#P-value for treatment in the models are significant(less than 0.05) and reduces 
#from 0.02993 to 0.0159.
#Unfortunately, p-values for mixed models aren’t as straightforward as they are 
#for the linear model.

#Rather than getting a p-value straightforwardly from your model, we get a p-value from a
#comparison of two models.

#Thus we focus on the Likelihood Ratio Test as a means to attain p-values.
#Likelihood is the probability of seeing the data you collected given your model.
#The logic of the likelihood ratio test is to compare the likelihood of two models
#with each other. First, the model without the factor that you’re interested in (the
#null model), then the model with the factor that you’re interested in.
```


```{r comparemodels}
#3. We have two models to compare with each other – one with the effect in
#question, one without the effect in question. 
#We perform the likelihood ratio test using the anova() function:

anova(lmmtreatment.null,lmmtreatment)

#we compared a full model (with the fixed effects in question) against a reduced(null) 
#model without the effects in question. 
#we conclude that a fixed effect treatment is significant as the difference between the
#likelihood of these two models is significant.

#treatment(providing primary school pupils with a free meal on school days) affected total 
#attendance (chisq.(1)=5.8116, p=0.01592), increasing it by about 8.406(8pupils) ± 3.486(3 pupils)
```

```{r Random intercepts}

coef(lmmtreatment)

#You see that each district is assigned a different intercept given that we’ve told the 
#model with “(1|district_id)”

#Note also that the fixed effects (treatment and total_enrolled) are all the same for all
#district_id. Our model is what is called a random intercept model. 
#In this model, we account for baseline-differences in total attended, but we assume that
#whatever the effect of treatment is, it’s going to be the same for all subjects and items.

#But is that a valid assumption? often times it’s not – it is quite expected
#that some district-id would elicit more or less treatments. That is, the effect of
#providing meals might be different for different district-id.

```

```{r Random slopes}
#Thus what we need is a random slope model, where district_id is not only allowed to have 
#differing intercepts,but where they are also allowed to have different slopes for the 
#effect of providing meals

lmmtreatmentRS <- lmer(total_attended ~ treatment + total_enrolled + 
        (1+treatment|district_id), data = ds_sdmerger1, REML = FALSE)
summary(lmmtreatmentRS)

lmmtreatmentRS.null <- lmer(total_attended ~ total_enrolled + (1+treatment|district_id), 
        data = ds_sdmerger1, REML = FALSE)
summary(lmmtreatmentRS.null)

#The notation “(1+treatment | district_id)” means that you tell the model to expect differing 
#baseline-levels of total_attended (the intercept, represented by 1) as well as differing
#responses to the main factor which is “treatment” in this case

anova(lmmtreatmentRS.null,lmmtreatmentRS)

#we conclude that a fixed effect treatment for random slope model is not significant as the 
#difference between the likelihood of these two models is 0.1254.(greater than 0.05)

coef(lmmtreatmentRS)

```














